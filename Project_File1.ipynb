{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vr7Kb0_F7jo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27c8d11-397f-4f33-a94c-b2f6931c9289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGRt8svV8Qx3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4VnguXpYx8Mb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d5uvYhH-GJl"
      },
      "outputs": [],
      "source": [
        "dataset_dir_img = \"gdrive/MyDrive/flickr30k_images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk59E4hd-fSN"
      },
      "outputs": [],
      "source": [
        "image_data = []\n",
        "\n",
        "for root, dirs, files in os.walk(os.path.join(dataset_dir_img, \"flickr30k_images\")):\n",
        "    for file in files:\n",
        "        # Check if the file is an image file\n",
        "        if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            # Construct the full file path\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # Load the image using PIL\n",
        "            image = Image.open(file_path)\n",
        "            image_data.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCH1RhTG-lgP"
      },
      "outputs": [],
      "source": [
        "dataset_dir_csv = \"gdrive/MyDrive/flickr30k_images/results.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdPsL6TW-sCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee6fcca-0a2d-44ac-f791-8f144c2efac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       image_name  comment_number  \\\n",
            "0  1000092795.jpg               0   \n",
            "1  1000092795.jpg               1   \n",
            "2  1000092795.jpg               2   \n",
            "3  1000092795.jpg               3   \n",
            "4  1000092795.jpg               4   \n",
            "\n",
            "                                             comment  \n",
            "0   Two young guys with shaggy hair look at their...  \n",
            "1   Two young , White males are outside near many...  \n",
            "2   Two men in green shirts are standing in a yard .  \n",
            "3       A man in a blue shirt standing in a garden .  \n",
            "4            Two friends enjoy time spent together .  \n"
          ]
        }
      ],
      "source": [
        "with open(dataset_dir_csv, 'r') as file:\n",
        "    # Read the first line to get the column names\n",
        "    columns = file.readline().strip().split('|')\n",
        "\n",
        "    # Read remaining lines, split by the '|' separator, and construct the DataFrame\n",
        "    data = [line.strip().split('|') for line in file]\n",
        "\n",
        "    # Create a DataFrame from the parsed data with the extracted column names\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Now you have the DataFrame `df` containing data from the CSV file\n",
        "# You can access columns like `image_name`, `comment_number`, and `comment`\n",
        "print(df.head())  # Example: print the first few rows of the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSH1E9CVAiO-",
        "outputId": "6affdee9-dead-4ed7-ecc4-9137cbb3e33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       image_name  comment_number  \\\n",
            "0  1000092795.jpg               0   \n",
            "1  1000092795.jpg               1   \n",
            "2  1000092795.jpg               2   \n",
            "3  1000092795.jpg               3   \n",
            "4  1000092795.jpg               4   \n",
            "\n",
            "                                             comment  \n",
            "0   Two young guys with shaggy hair look at their...  \n",
            "1   Two young , White males are outside near many...  \n",
            "2   Two men in green shirts are standing in a yard .  \n",
            "3       A man in a blue shirt standing in a garden .  \n",
            "4            Two friends enjoy time spent together .  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(dataset_dir_csv, delimiter='|')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "df[' comment'] = df[' comment'].astype(str)\n"
      ],
      "metadata": {
        "id": "w7BrhiO419i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_captions_df = df.groupby('image_name')[' comment'].apply(lambda x: ' '.join(x)).reset_index()\n"
      ],
      "metadata": {
        "id": "YM3lZiQNcAN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_captions_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe8JThonnspx",
        "outputId": "18e34fb3-5b1a-4542-b933-7d9374932a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['image_name', ' comment'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(combined_captions_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFh_s8CqnvKe",
        "outputId": "7ed2a6ee-424a-424e-a9eb-b6e2a0f1f9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31783"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Extract image IDs from file paths\n",
        "image_paths = []\n",
        "\n",
        "for root, dirs, files in os.walk(os.path.join(dataset_dir_img, \"flickr30k_images\")):\n",
        "    for file in files:\n",
        "        if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "\n",
        "            file_path = os.path.join(root, file)\n",
        "            # Extract the image ID from the file path (assuming it's part of the file name)\n",
        "            image_id = os.path.splitext(file)[0]\n",
        "            image_paths.append((image_id, file_path))\n",
        "\n",
        "# Map image IDs to image paths\n",
        "id_to_path = dict(image_paths)\n",
        "\n",
        "# Match image names with image IDs and get corresponding file paths\n",
        "image_paths_matched = []\n",
        "\n",
        "for image_name in combined_captions_df['image_name']:\n",
        "#for image_name in df['image_name']:\n",
        "\n",
        "    # Extract image ID from image name\n",
        "    image_id = os.path.splitext(image_name)[0]\n",
        "    # Get the corresponding file path using the image ID\n",
        "    file_path = id_to_path.get(image_id)\n",
        "    if file_path:\n",
        "        image_paths_matched.append(file_path)\n",
        "    else:\n",
        "        image_paths_matched.append(None)  # Or any placeholder value for missing images\n",
        "\n",
        "# Add image_paths_matched as a new column to the DataFrame\n",
        "combined_captions_df['image_path'] = image_paths_matched\n",
        "#df['image_path'] = image_paths_matched\n"
      ],
      "metadata": {
        "id": "5KRIq1GQqCrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_captions_df['image_path'].head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz-rOH4veoSx",
        "outputId": "684f3533-7086-4764-cfd4-95414b355fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    gdrive/MyDrive/flickr30k_images/flickr30k_imag...\n",
              "1    gdrive/MyDrive/flickr30k_images/flickr30k_imag...\n",
              "2    gdrive/MyDrive/flickr30k_images/flickr30k_imag...\n",
              "Name: image_path, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIzkrbrtKMd8",
        "outputId": "a3c6b153-2077-4efb-b9a7-1a605b84f4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foZ-BzD_NpmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d790b4ca-4774-40bc-aa86-cada986765ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Check if text is a string\n",
        "        # Lowercasing\n",
        "        text = text.lower()\n",
        "\n",
        "        # Tokenization\n",
        "        tokens = word_tokenize(text)\n",
        "\n",
        "        # Removing Punctuation\n",
        "        tokens = [token for token in tokens if token not in string.punctuation]\n",
        "\n",
        "        # Removing Stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "        # Stemming\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        return tokens\n",
        "    else:\n",
        "        return []  # Return an empty list for non-string inputs\n",
        "\n",
        "combined_captions_df['preprocessed_comment'] = combined_captions_df[' comment'].apply(preprocess_text)\n",
        "#df['preprocessed_comment'] = df[' comment'].apply(preprocess_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVUfsAQxKFpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbdbc530-e320-4cf9-a3ec-1725fe6afa40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [two, young, guy, shaggi, hair, look, hand, ha...\n",
              "1        [sever, men, hard, hat, oper, giant, pulley, s...\n",
              "2        [child, pink, dress, climb, set, stair, entri,...\n",
              "3        [someon, blue, shirt, hat, stand, stair, lean,...\n",
              "4        [two, men, one, gray, shirt, one, black, shirt...\n",
              "                               ...                        \n",
              "31778    [woman, write, pad, room, gold, decor, wall, w...\n",
              "31779    [person, red, shirt, climb, rock, face, cover,...\n",
              "31780    [two, male, construct, worker, work, street, o...\n",
              "31781    [older, busker, glass, play, eastern, string, ...\n",
              "31782    [man, short, hawaiian, shirt, lean, rail, pilo...\n",
              "Name: preprocessed_comment, Length: 31783, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "combined_captions_df['preprocessed_comment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu6x4E1fKIXL"
      },
      "outputs": [],
      "source": [
        "df_temp = pd.DataFrame(columns=combined_captions_df.columns)\n",
        "\n",
        "df_temp=combined_captions_df.head(50).copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_temp['preprocessed_comment'] = df_temp['preprocessed_comment'].apply(lambda x: ' '.join(word for word in x))\n",
        "df_temp['preprocessed_comment']"
      ],
      "metadata": {
        "id": "pGZ075Ccl9HP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxv3btaXZb6N",
        "outputId": "e8833d3d-3e6a-4f7d-f748-886ab656a86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "captions = df_temp['preprocessed_comment'].head(5)  # Select a few captions for inspection\n",
        "\n",
        "# Tokenize the captions\n",
        "tokenized_sequences = tokenizer.texts_to_sequences(captions)\n",
        "\n",
        "# Print the original captions and their tokenized sequences\n",
        "for caption, sequence in zip(captions, tokenized_sequences):\n",
        "    print(\"Original Caption:\", caption)\n",
        "    print(\"Tokenized Sequence:\", sequence)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Gg9Wldd0pv",
        "outputId": "e8bf6fc5-6c7a-4904-bf92-73672960df89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Caption: ['two', 'young', 'guy', 'shaggi', 'hair', 'look', 'hand', 'hang', 'yard', 'two', 'young', 'white', 'male', 'outsid', 'near', 'mani', 'bush', 'two', 'men', 'green', 'shirt', 'stand', 'yard', 'man', 'blue', 'shirt', 'stand', 'garden', 'two', 'friend', 'enjoy', 'time', 'spent', 'togeth']\n",
            "Tokenized Sequence: [12, 20, 217, 78, 205, 149, 12, 20, 13, 41, 12, 25, 46, 26, 173, 149, 3, 28, 26, 173, 208, 12, 321, 209, 322]\n",
            "\n",
            "Original Caption: ['sever', 'men', 'hard', 'hat', 'oper', 'giant', 'pulley', 'system', 'worker', 'look', 'piec', 'equip', 'two', 'men', 'work', 'machin', 'wear', 'hard', 'hat', 'four', 'men', 'top', 'tall', 'structur', 'three', 'men', 'larg', 'rig']\n",
            "Tokenized Sequence: [25, 63, 30, 324, 325, 326, 480, 205, 12, 25, 591, 63, 30, 36, 25, 58, 113, 84, 25, 331]\n",
            "\n",
            "Original Caption: ['child', 'pink', 'dress', 'climb', 'set', 'stair', 'entri', 'way', 'littl', 'girl', 'pink', 'dress', 'go', 'wooden', 'cabin', 'littl', 'girl', 'climb', 'stair', 'playhous', 'littl', 'girl', 'climb', 'wooden', 'playhous', 'girl', 'go', 'wooden', 'build']\n",
            "Tokenized Sequence: [114, 115, 153, 332, 336, 334, 23, 115, 153, 624, 87, 335, 23, 336, 23, 87, 23, 624, 87]\n",
            "\n",
            "Original Caption: ['someon', 'blue', 'shirt', 'hat', 'stand', 'stair', 'lean', 'window', 'man', 'blue', 'shirt', 'stand', 'ladder', 'clean', 'window', 'man', 'ladder', 'clean', 'window', 'tall', 'build', 'man', 'blue', 'shirt', 'jean', 'ladder', 'clean', 'window', 'man', 'ladder', 'clean', 'window']\n",
            "Tokenized Sequence: [28, 26, 30, 173, 336, 64, 3, 28, 26, 173, 117, 64, 3, 117, 64, 113, 3, 28, 26, 117, 64, 3, 117, 64]\n",
            "\n",
            "Original Caption: ['two', 'men', 'one', 'gray', 'shirt', 'one', 'black', 'shirt', 'stand', 'near', 'stove', 'two', 'guy', 'cook', 'joke', 'around', 'camera', 'two', 'men', 'kitchen', 'cook', 'food', 'stove', 'two', 'men', 'stove', 'prepar', 'food', 'two', 'men', 'cook', 'meal']\n",
            "Tokenized Sequence: [12, 25, 65, 89, 26, 65, 18, 26, 173, 41, 154, 12, 217, 118, 119, 12, 25, 341, 218, 154, 12, 25, 154, 218, 12, 25, 343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di88wj3WwwDZ",
        "outputId": "5b4af928-ebdb-4d15-c7be-d2eecacb1a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "542"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "#df_temp['preprocessed_comment'] = df_temp['preprocessed_comment'].apply(lambda x: ''.join(x))\n",
        "\n",
        "# Load pre-trained ResNet50 model (excluding top layers)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "image_model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "# Function to extract features from an image\n",
        "def extract_image_features(image_path, model):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((224, 224))  # Resize image to match input size expected by ResNet50\n",
        "    img_array = np.array(img)\n",
        "    img_array = preprocess_input(img_array)  # Preprocess input image\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    features = model.predict(img_array)  # Extract features\n",
        "    return features\n",
        "\n",
        "# Custom data generator\n",
        "\n",
        "def custom_data_generator(data_keys, mapping, image_paths, tokenizer, max_length, vocab_size, batch_size):\n",
        "    while True:\n",
        "        for key, image_path in zip(data_keys, image_paths):\n",
        "            # Extract image features\n",
        "            image_features = extract_image_features(image_path, image_model)\n",
        "\n",
        "            caption = mapping[key]  # Get the single caption associated with the image\n",
        "\n",
        "            # Process the single caption\n",
        "            sequence = [tokenizer.word_index[word] for word in caption]\n",
        "\n",
        "            # Generate input and output sequences\n",
        "            for i in range(1, len(sequence)):\n",
        "                # Prepare input sequence\n",
        "                input_seq = sequence[:i]\n",
        "                input_seq = pad_sequences([input_seq], maxlen=max_length, padding='post')[0]\n",
        "\n",
        "                # Prepare output sequence (next word index)\n",
        "                output_seq = sequence[i]\n",
        "\n",
        "                # Pad the output sequence to match the length of the input sequence\n",
        "                #output_seq = pad_sequences([[output_seq]], maxlen=max_length, padding='post')[0]\n",
        "\n",
        "                # Convert output_seq to one-hot encoding\n",
        "                output_seq = to_categorical(output_seq, num_classes=vocab_size)\n",
        "\n",
        "                # Reshape the output sequence to match the model's output shape\n",
        "                output_seq = output_seq.reshape(1, 1, vocab_size)\n",
        "                print('output_seq',len(output_seq))\n",
        "                print('input_seq',len(input_seq))\n",
        "                # Yield the data\n",
        "                yield [image_features, np.array(input_seq)[np.newaxis, ...]], output_seq\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the data keys, mapping, and tokenizer\n",
        "data_keys = df_temp['image_name']\n",
        "mapping = dict(zip(df_temp['image_name'], df_temp['preprocessed_comment']))\n",
        "#tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "#tokenizer.fit_on_texts(df_temp['preprocessed_comment'])\n",
        "\n",
        "# Define the list of all comments\n",
        "all_comments = df_temp['preprocessed_comment'].tolist()\n",
        "# Concatenate all comments into a single string\n",
        "all_comments_text = ' '.join(map(str, all_comments))\n",
        "# Split the concatenated text into unique words\n",
        "unique_words = set(all_comments_text.split())\n",
        "# Get the count of unique words\n",
        "num_unique_words = len(unique_words)\n",
        "# Initialize the Tokenizer with the correct vocabulary size\n",
        "tokenizer = Tokenizer(num_words=num_unique_words)\n",
        "# Fit the Tokenizer on the text data\n",
        "tokenizer.fit_on_texts(all_comments)\n",
        "# Get the vocabulary size (including reserved tokens)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Define parameters\n",
        "max_length = 52\n",
        "batch_size = 32\n",
        "\n",
        "# Define image paths\n",
        "image_paths = df_temp['image_path'].tolist()\n",
        "\n",
        "# Instantiate the custom data generator\n",
        "generator = custom_data_generator(data_keys, mapping, image_paths, tokenizer, max_length, vocab_size, batch_size)\n",
        "#generator = custom_data_generator(data_keys, mapping, image_paths, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Define multimodal model\n",
        "def create_multimodal_model(max_length, vocab_size):\n",
        "    # Image feature layers\n",
        "    image_features_input = tf.keras.layers.Input(shape=(2048,))\n",
        "    image_features_reshaped = tf.keras.layers.Reshape((1, 1, 2048))(image_features_input)\n",
        "\n",
        "    # Text feature layers\n",
        "    text_input = tf.keras.layers.Input(shape=(max_length,))\n",
        "    embedding_layer = tf.keras.layers.Embedding(vocab_size, 256, mask_zero=True)(text_input)\n",
        "    sequence_dropout = tf.keras.layers.Dropout(0.4)(embedding_layer)\n",
        "\n",
        "    # Transformer layer for text processing\n",
        "    transformer_layer = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=256, dropout=0.2)(sequence_dropout, sequence_dropout)\n",
        "    text_features = tf.keras.layers.GlobalAveragePooling1D()(transformer_layer)\n",
        "    text_features = tf.keras.layers.Reshape((1, 1, 256))(text_features)\n",
        "\n",
        "    # Combine image and text features\n",
        "    merged_features = tf.keras.layers.Concatenate()([image_features_reshaped, text_features])\n",
        "    dense1 = tf.keras.layers.Dense(256, activation='relu')(merged_features)\n",
        "    output = tf.keras.layers.Dense(vocab_size, activation='softmax')(dense1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[image_features_input, text_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "# Create the multimodal model\n",
        "multimodal_model = create_multimodal_model(max_length, vocab_size)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "multimodal_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the generator\n",
        "steps_per_epoch = len(data_keys) // batch_size  # Adjust if necessary\n",
        "multimodal_model.fit(generator, epochs=20, steps_per_epoch=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "y2rABqKLUcdx",
        "outputId": "ed4fe207-2f05-4945-dfb7-6dd55e93eeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_temp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7033c722e90>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Define the data keys, mapping, and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mdata_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessed_comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m#tokenizer = tf.keras.preprocessing.text.Tokenizer()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_temp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_comments = df_temp['preprocessed_comment'].tolist()\n",
        "all_comments_text = ' '.join(map(str, all_comments))\n",
        "unique_words = set(all_comments_text.split())\n",
        "num_unique_words = len(unique_words)\n",
        "print(num_unique_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiWPH8UKuqa9",
        "outputId": "5b758fd6-2488-4e4d-a212-08044abebce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "594\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}