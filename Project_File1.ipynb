{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41135,"status":"ok","timestamp":1710937857854,"user":{"displayName":"Group Project","userId":"06287715802694872938"},"user_tz":-60},"id":"vr7Kb0_F7jo2","outputId":"934f1247-7739-49dc-9de4-038e886bc7e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGRt8svV8Qx3"},"outputs":[],"source":["import os\n","import pandas as pd\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_d5uvYhH-GJl"},"outputs":[],"source":["dataset_dir_img = \"gdrive/MyDrive/flickr30k_images/flickr30k_images\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nk59E4hd-fSN"},"outputs":[],"source":["image_data = []\n","for root, dirs, files in os.walk(os.path.join(dataset_dir_img, \"images\")):\n","    for file in files:\n","        # Check if the file is an image file\n","        if file.endswith((\".jpg\", \".jpeg\", \".png\")):\n","            # Construct the full file path\n","            file_path = os.path.join(root, file)\n","\n","            # Load the image using PIL\n","            image = Image.open(file_path)\n","            image_data.append(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCH1RhTG-lgP"},"outputs":[],"source":["dataset_dir_csv = \"gdrive/MyDrive/flickr30k_images/results.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":952,"status":"ok","timestamp":1710937979336,"user":{"displayName":"Group Project","userId":"06287715802694872938"},"user_tz":-60},"id":"qdPsL6TW-sCi","outputId":"aba79a22-2aaa-4037-d975-f22e9855107f"},"outputs":[{"output_type":"stream","name":"stdout","text":["       image_name  comment_number  \\\n","0  1000092795.jpg               0   \n","1  1000092795.jpg               1   \n","2  1000092795.jpg               2   \n","3  1000092795.jpg               3   \n","4  1000092795.jpg               4   \n","\n","                                             comment  \n","0   Two young guys with shaggy hair look at their...  \n","1   Two young , White males are outside near many...  \n","2   Two men in green shirts are standing in a yard .  \n","3       A man in a blue shirt standing in a garden .  \n","4            Two friends enjoy time spent together .  \n"]}],"source":["with open(dataset_dir_csv, 'r') as file:\n","    # Read the first line to get the column names\n","    columns = file.readline().strip().split('|')\n","\n","    # Read remaining lines, split by the '|' separator, and construct the DataFrame\n","    data = [line.strip().split('|') for line in file]\n","\n","    # Create a DataFrame from the parsed data with the extracted column names\n","    df = pd.DataFrame(data, columns=columns)\n","\n","# Now you have the DataFrame `df` containing data from the CSV file\n","# You can access columns like `image_name`, `comment_number`, and `comment`\n","print(df.head())  # Example: print the first few rows of the DataFrame"]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7BrhiO419i8","executionInfo":{"status":"ok","timestamp":1710937981225,"user_tz":-60,"elapsed":8,"user":{"displayName":"Group Project","userId":"06287715802694872938"}},"outputId":"b2e630b0-2d04-46e9-efb9-ad006997a140"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['image_name', ' comment_number', ' comment'], dtype='object')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1710850358486,"user":{"displayName":"Group Project","userId":"06287715802694872938"},"user_tz":-330},"id":"dSH1E9CVAiO-","outputId":"797698d3-f613-4430-ae2b-cd44b3f8d75c"},"outputs":[{"output_type":"stream","name":"stdout","text":["       image_name  comment_number  \\\n","0  1000092795.jpg               0   \n","1  1000092795.jpg               1   \n","2  1000092795.jpg               2   \n","3  1000092795.jpg               3   \n","4  1000092795.jpg               4   \n","\n","                                             comment  \n","0   Two young guys with shaggy hair look at their...  \n","1   Two young , White males are outside near many...  \n","2   Two men in green shirts are standing in a yard .  \n","3       A man in a blue shirt standing in a garden .  \n","4            Two friends enjoy time spent together .  \n"]}],"source":["df = pd.read_csv(dataset_dir_csv, delimiter='|')\n","\n","# Display the first few rows of the DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5257,"status":"ok","timestamp":1710850363736,"user":{"displayName":"Group Project","userId":"06287715802694872938"},"user_tz":-330},"id":"BIzkrbrtKMd8","outputId":"bbdb6556-11ba-4dbe-efd7-285ffbbd8928"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foZ-BzD_NpmX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710850366163,"user_tz":-330,"elapsed":2435,"user":{"displayName":"Group Project","userId":"06287715802694872938"}},"outputId":"1596b51b-6e14-48bc-b35c-c20622cec923"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import string\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","def preprocess_text(text):\n","    if isinstance(text, str):  # Check if text is a string\n","        # Lowercasing\n","        text = text.lower()\n","\n","        # Tokenization\n","        tokens = word_tokenize(text)\n","\n","        # Removing Punctuation\n","        tokens = [token for token in tokens if token not in string.punctuation]\n","\n","        # Removing Stopwords\n","        stop_words = set(stopwords.words('english'))\n","        tokens = [token for token in tokens if token not in stop_words]\n","\n","        # Stemming\n","        stemmer = PorterStemmer()\n","        tokens = [stemmer.stem(token) for token in tokens]\n","\n","        return tokens\n","    else:\n","        return []  # Return an empty list for non-string inputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVUfsAQxKFpL"},"outputs":[],"source":["df['preprocessed_comment'] = df[' comment'].apply(preprocess_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1710850443962,"user":{"displayName":"Group Project","userId":"06287715802694872938"},"user_tz":-330},"id":"yu6x4E1fKIXL","outputId":"ca6c4941-f9bd-4a30-99a7-0a51f3b3297e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         [two, young, guy, shaggi, hair, look, hand, ha...\n","1         [two, young, white, male, outsid, near, mani, ...\n","2                     [two, men, green, shirt, stand, yard]\n","3                         [man, blue, shirt, stand, garden]\n","4                 [two, friend, enjoy, time, spent, togeth]\n","                                ...                        \n","158910    [man, short, hawaiian, shirt, lean, rail, pilo...\n","158911    [young, man, hang, side, boat, like, fog, roll...\n","158912    [man, lean, side, blue, white, boat, sit, bodi...\n","158913    [man, ride, small, boat, harbor, fog, mountain...\n","158914    [man, moor, blue, white, boat, hill, mist, bac...\n","Name: preprocessed_comment, Length: 158915, dtype: object"]},"metadata":{},"execution_count":11}],"source":["df['preprocessed_comment']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRKfvC1OOBJ2","executionInfo":{"status":"error","timestamp":1710850444516,"user_tz":-330,"elapsed":597,"user":{"displayName":"Group Project","userId":"06287715802694872938"}},"outputId":"fc8bd442-ed6b-4efb-bae6-ae63203ae379"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'TfidfVectorizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-397f222ff5c7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Extract keywords for each row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkeywords_per_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessed_comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"]}],"source":["tfidf_vectorizer = TfidfVectorizer()\n","\n","# Extract keywords for each row\n","keywords_per_row = []\n","for row in df['preprocessed_comment']:\n","    # Convert preprocessed comment to string\n","    comment_str = ' '.join(row)\n","\n","    # Fit the vectorizer and transform the comment\n","    tfidf_matrix = tfidf_vectorizer.fit_transform([comment_str])\n","\n","    # Get feature names (words)\n","    feature_names = tfidf_vectorizer.get_feature_names_out()\n","\n","    # Get top N keywords based on highest TF-IDF scores\n","    top_keywords_indices = tfidf_matrix.sum(axis=0).argsort()[0, ::-1][:5]\n","    top_keywords = [feature_names[idx] for idx in top_keywords_indices]\n","\n","    # Store keywords for this row\n","    keywords_per_row.append(top_keywords)\n","\n","# Add extracted keywords as a new column in the DataFrame\n","df['keywords'] = keywords_per_row"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XJQceLXyOKIl"},"outputs":[],"source":["df['keywords']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSbVUe7aPigl"},"outputs":[],"source":["top_keywords_tfidf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5lCIwg0PqFQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyN5GkqfmVBZfd/mvzMCCQ0e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}